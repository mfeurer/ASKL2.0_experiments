{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import openml\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "from plot_utils.style import style_dc\n",
    "from plot_utils.common_plots import rank, average_plot\n",
    "from plot_utils.common_tables import collect_data_for_final_table, do_wilcoxon_test\n",
    "from plot_utils.common_loading import load_from_openml\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/eggenspk/Work/Project/2020_PoSH_Autosklearn/2020_IEEE_Autosklearn_experiments/experiment_scripts/\")\n",
    "sys.path.append(\"/home/feurerm/sync_dir/projects/2020_posh/2020_IEEE_Autosklearn_experiments/experiment_scripts\")\n",
    "from utils import openml_automl_benchmark, get_normalization_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = getpass.getuser()\n",
    "dir_ = {\n",
    "    'eggenspk': \"/media/eggenspk/04a9389c-b7e2-474a-a9de-c66d5345f407/2020_posh/\",\n",
    "    'feurerm': \"/home/feurerm/projects/2020_posh/\",\n",
    "}[username]\n",
    "\n",
    "valid_pretty = {\n",
    "    10: {\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    (None, \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    },\n",
    "    60: {\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    (None, \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    },\n",
    "    #36000: {\n",
    "    #(\"auto\", \"10H/AutoAuto_simulate/dynamic/None/autoauto\"): \"dynamic\",\n",
    "    #(\"auto\", \"10H/AutoAuto_simulate/static/None/autoauto\"): \"single best\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    #(None, \"10H/ASKL_run_with_portfolio/3600/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    #},\n",
    "}\n",
    "\n",
    "task_ids = openml_automl_benchmark\n",
    "\n",
    "res_dc = {}\n",
    "miss = 0\n",
    "for horizon in list(valid_pretty.keys()):\n",
    "    res_dc[horizon] = {}\n",
    "    for tid in task_ids:\n",
    "        res_dc[horizon][tid] = {}\n",
    "        for mode in list(valid_pretty[horizon].keys()):\n",
    "            if type(mode) == tuple:\n",
    "                auto, model_name = mode\n",
    "            else:\n",
    "                model_name = mode\n",
    "                auto = None\n",
    "            res_dc[horizon][tid][mode] = []\n",
    "            for seed in range(10):\n",
    "                fl_tmpl = dir_ + \"/\" + model_name + \"_%d_%d_0_0/result.json\" % (tid, seed)\n",
    "                fl = glob.glob(fl_tmpl)               \n",
    "                if len(fl) == 0:\n",
    "                    miss += 1\n",
    "                    print(fl_tmpl)\n",
    "                    continue\n",
    "                fl = fl[0]\n",
    "                with open(fl, \"r\") as fh:\n",
    "                    line = json.load(fh)\n",
    "                    loss = line[\"0\"][\"trajectory\"]\n",
    "                    loss = [(l[0], l[1]) for l in loss]\n",
    "                    loss = dict(loss)\n",
    "                    res_dc[horizon][tid][mode].append(loss)\n",
    "print(\"Missing %d entries\" % miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some stuff from disc and openml - takes some time\n",
    "tasks, task_ids_sorted_by_num_features = load_from_openml(task_ids)\n",
    "min_diff_dc = get_normalization_constants(dir_, load=True)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HORIZON = 10\n",
    "for tid in task_ids_sorted_by_num_features:\n",
    "    plt.figure(figsize=[16,12])\n",
    "    colors = itertools.cycle(COLORS)\n",
    "    for mode in list(valid_pretty[HORIZON].keys()):\n",
    "        c = next(colors)\n",
    "        tmp = pd.DataFrame(res_dc[HORIZON][tid][mode]).sort_index(axis=1).ffill(axis=1)\n",
    "        med = tmp.median(axis=0)\n",
    "        med.loc[HORIZON*60] = med.iloc[-1]\n",
    "        low = tmp.quantile(0.25)\n",
    "        low.loc[HORIZON*60] = low.iloc[-1]\n",
    "        up = tmp.quantile(0.75, axis=0)\n",
    "        up.loc[HORIZON*60] = up.iloc[-1]\n",
    "        plt.plot(med.index, med.to_numpy(), label=valid_pretty[HORIZON][mode], linewidth=3)\n",
    "        plt.fill_between(med.index, low, up, alpha=0.3)\n",
    "    plt.title('Name: %s (%d), #instances: %d, #attributes: %d' % (\n",
    "        tasks.loc[tid, 'name'], tid, tasks.loc[tid, 'NumberOfInstances'], tasks.loc[tid, 'NumberOfFeatures']))\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.ylim([plt.ylim()[0], plt.ylim()[0] + 0.3*(plt.ylim()[1]-plt.ylim()[0])])\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot average BER across all datasets\n",
    "HORIZON = 10\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    model_list.append(m)\n",
    "average_plot(model_list=model_list, res_dc=res_dc, valid_pretty=valid_pretty,\n",
    "             horizon=HORIZON, task_ids_sorted_by_num_features=task_ids_sorted_by_num_features,\n",
    "             min_diff_dc=min_diff_dc)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average BER across all datasets\n",
    "HORIZON = 60\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    model_list.append(m)\n",
    "average_plot(model_list=model_list, res_dc=res_dc, valid_pretty=valid_pretty,\n",
    "             horizon=HORIZON, task_ids_sorted_by_num_features=task_ids_sorted_by_num_features,\n",
    "             min_diff_dc=min_diff_dc)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Box plots\n",
    "lims = {\n",
    "    \"robert\": [0.53, 0.65],\n",
    "    \"fabert\": [0.31, 0.37],\n",
    "    \"nomao\": [0.033, 0.047],\n",
    "}\n",
    "\n",
    "for horizon in res_dc:\n",
    "    model_list = sorted(list(valid_pretty[horizon].keys()), key=lambda x: \"SH\" in x[1])\n",
    "    for tid in task_ids_sorted_by_num_features:\n",
    "        losses = {}\n",
    "        for m in model_list:\n",
    "            data = res_dc[horizon][tid][m]\n",
    "            assert len(data) == 10\n",
    "            final_losses = []\n",
    "            for traj in data:\n",
    "                keys = np.sort(list(traj.keys()))\n",
    "                l = traj[keys[-1]]\n",
    "                final_losses.append(l)\n",
    "            losses[m] = np.array(final_losses)\n",
    "        labels = [valid_pretty[horizon][m] for m in model_list]\n",
    "        plt.boxplot(\n",
    "            [losses[m] for m in model_list[:4]],\n",
    "            positions=np.arange(4),\n",
    "            labels=labels[:4],\n",
    "            boxprops={\"linewidth\": 2},\n",
    "            whiskerprops={\"linewidth\": 2},\n",
    "            capprops={\"linewidth\": 2},\n",
    "            medianprops={\"linewidth\": 3, \"c\": style_dc[\"colors\"][0]},\n",
    "            flierprops={\"marker\": \"+\", \"markersize\": 10, \"markeredgewidth\": 2}\n",
    "                   )\n",
    "        plt.boxplot(\n",
    "            [losses[m] for m in model_list[4:]],\n",
    "            positions=np.arange(4, 8),\n",
    "            labels=labels[4:],\n",
    "            boxprops={\"linewidth\": 2},\n",
    "            whiskerprops={\"linewidth\": 2},\n",
    "            capprops={\"linewidth\": 2},\n",
    "            medianprops={\"linewidth\": 3, \"c\": style_dc[\"colors\"][1]},\n",
    "            flierprops={\"marker\": \"+\", \"markersize\": 10, \"markeredgewidth\": 2}\n",
    "                   )\n",
    "        plt.xticks(rotation=90, fontsize=style_dc[\"fontsize\"])\n",
    "        plt.yticks(fontsize=style_dc[\"fontsize\"])\n",
    "        plt.ylabel(\"balanced error rate\", fontsize=style_dc[\"fontsize\"])\n",
    "        title = \"%dmin %s [%dx%d]\"\n",
    "        plt.title(title % (horizon, tasks.loc[tid, 'name'], tasks.loc[tid, 'NumberOfInstances'], \n",
    "                           tasks.loc[tid, 'NumberOfFeatures']),\n",
    "                 fontsize=style_dc[\"fontsize\"])\n",
    "        if tasks.loc[tid, 'name'] in lims:\n",
    "            plt.ylim(lims[tasks.loc[tid, 'name']])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assume we have either all or no models\n",
    "horizon_list = sorted(list(valid_pretty.keys()))\n",
    "model_list = {}\n",
    "for h in horizon_list:\n",
    "    model_list[h] = []\n",
    "    for m in valid_pretty[h].keys():\n",
    "        model_list[h].append(m)\n",
    "\n",
    "tab_data, stat_test_data = collect_data_for_final_table(model_list, res_dc, valid_pretty, horizon_list,\n",
    "                                                        task_ids_sorted_by_num_features, min_diff_dc)\n",
    "not_different = do_wilcoxon_test(stat_test_data, model_list, horizon_list, valid_pretty, exclude=[\"oracle\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tab_data)\n",
    "#for horizon in horizon_list:\n",
    "#    df['Rank_%s' % horizon] = df[horizon].rank(method='average', ascending=True)\n",
    "print(df.to_latex())\n",
    "print(not_different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 60\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    if \"oracle\" in m[1]:\n",
    "        continue\n",
    "    model_list.append(m)\n",
    "rank(model_list, res_dc, valid_pretty, HORIZON, task_ids_sorted_by_num_features, n_iter=200, steplength=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
