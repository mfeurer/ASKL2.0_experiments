{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import openml\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "from plot_utils.style import style_dc\n",
    "from plot_utils.common_plots import rank, average_plot\n",
    "from plot_utils.common_tables import collect_data_for_final_table, do_wilcoxon_test\n",
    "from plot_utils.common_loading import load_from_openml\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/eggenspk/Work/Project/2020_PoSH_Autosklearn/2020_IEEE_Autosklearn_experiments/experiment_scripts/\")\n",
    "sys.path.append(\"/home/feurerm/sync_dir/projects/2020_posh/2020_IEEE_Autosklearn_experiments/experiment_scripts\")\n",
    "from utils import openml_automl_benchmark, get_normalization_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "username = getpass.getuser()\n",
    "dir_ = {\n",
    "    'eggenspk': \"/media/eggenspk/04a9389c-b7e2-474a-a9de-c66d5345f407/2020_posh/\",\n",
    "    'feurerm': \"/home/feurerm/projects/2020_posh/\",\n",
    "}[username]\n",
    "\n",
    "valid_pretty = {\n",
    "    10: {\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    ('portfolio', \"10MIN/ASKL_run_with_portfolio/60/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    ('bo', \"10MIN/ASKL_automldata/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    ('knd', \"10MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    },\n",
    "    60: {\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    ('portfolio', \"60MIN/ASKL_run_with_portfolio/360/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    ('bo', \"60MIN/ASKL_automldata/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_holdout_iterative_es_if\"): \"holdout\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_holdout_iterative_es_if\"): \"SH; holdout\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_3CV_iterative_es_if\"): \"3CV\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_3CV_iterative_es_if\"): \"SH; 3CV\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_5CV_iterative_es_if\"): \"5CV\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_5CV_iterative_es_if\"): \"SH; 5CV\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_None_10CV_iterative_es_if\"): \"10CV\",\n",
    "    ('knd', \"60MIN/ASKL_automldata_w_ensemble_w_knd/RF/RF_SH-eta4-i_10CV_iterative_es_if\"): \"SH; 10CV\",\n",
    "    },\n",
    "}\n",
    "\n",
    "task_ids = openml_automl_benchmark\n",
    "\n",
    "res_dc = {}\n",
    "per_cf_dc = {}\n",
    "miss = 0\n",
    "for horizon in list(valid_pretty.keys()):\n",
    "    res_dc[horizon] = {}\n",
    "    per_cf_dc[horizon] = {}\n",
    "    for tid in task_ids:\n",
    "        res_dc[horizon][tid] = {}\n",
    "        per_cf_dc[horizon][tid] = {}\n",
    "        for mode in list(valid_pretty[horizon].keys()):\n",
    "            if type(mode) == tuple:\n",
    "                auto, model_name = mode\n",
    "            else:\n",
    "                model_name = mode\n",
    "                auto = None\n",
    "            res_dc[horizon][tid][mode] = []\n",
    "            for seed in range(10):\n",
    "                if auto == \"auto\":\n",
    "                    fl_tmpl = dir_ + \"/\" + model_name + \"_%d_%d/result.json\" % (tid, seed)\n",
    "                elif auto == 'knd':\n",
    "                    fl_tmpl = dir_ + \"/\" + model_name + \"_%d_%d_25_0/result.json\" % (tid, seed)\n",
    "                else:\n",
    "                    fl_tmpl = dir_ + \"/\" + model_name + \"_%d_%d_0_0/result.json\" % (tid, seed)\n",
    "                fl = glob.glob(fl_tmpl)               \n",
    "                if len(fl) == 0:\n",
    "                    miss += 1\n",
    "                    print(fl_tmpl)\n",
    "                    continue\n",
    "                fl = fl[0]\n",
    "                with open(fl, \"r\") as fh:\n",
    "                    line = json.load(fh)\n",
    "                    loss = line[\"0\"][\"trajectory\"]\n",
    "                    loss = [(l[0], l[1]) for l in loss]\n",
    "                    loss = dict(loss)\n",
    "                    res_dc[horizon][tid][mode].append(loss)\n",
    "\n",
    "            \"\"\"\n",
    "            # get the same information per config\n",
    "            per_cf_dc[horizon][tid][mode] = []\n",
    "            for seed in range(10):\n",
    "                if auto == \"auto\":\n",
    "                    fl_tmpl = dir_ + \"/\" + model_name + \"_%d_%d/auto-sklearn-output/*/*/runhistory.json\" % (tid, seed)\n",
    "                elif 'knd':\n",
    "                    fl_tmpl = dir_ + \"/\" + model_name + \"_%d_%d_25_0/auto-sklearn-output/*/*/runhistory.json\" % (tid, seed)\n",
    "                else:\n",
    "                    fl_tmpl = dir_ + \"/\" + model_name + \"_%d_%d_0_0/auto-sklearn-output/*/*/runhistory.json\" % (tid, seed)\n",
    "                fl = glob.glob(fl_tmpl)               \n",
    "                if len(fl) == 0:\n",
    "                    if len(res_dc[horizon][tid][mode][seed]) == 1:\n",
    "                        traj = dict([(i, 1.0) for i in range(32)])\n",
    "                        per_cf_dc[horizon][tid][mode].append(traj)\n",
    "                        continue\n",
    "                    miss += 1\n",
    "                    print(fl_tmpl)\n",
    "                    continue\n",
    "                fl = fl[0]\n",
    "                with open(fl, \"r\") as fh:\n",
    "                    line = json.load(fh)   \n",
    "                    line = line[\"data\"]\n",
    "                    val_losses = []\n",
    "                    test_losses = []\n",
    "                    for i in range(len(line)):\n",
    "                        try:\n",
    "                            val_loss = line[i][1][0]\n",
    "                            try:\n",
    "                                # was this a crash?\n",
    "                                test_loss = line[i][1][3][\"test_loss\"]\n",
    "                            except:\n",
    "                                test_loss = 1\n",
    "                        except:\n",
    "                            val_loss = val_losses[-1]\n",
    "                            test_loss = test_losses[-1]\n",
    "                        val_losses.append(val_loss)\n",
    "                        test_losses.append(test_loss)\n",
    "                    traj = [test_losses[0], ]\n",
    "                    b = val_losses[0]\n",
    "                    for v, t in zip(val_losses[1:], test_losses[1:]):\n",
    "                        if v < b:\n",
    "                            b = v\n",
    "                            traj.append(t)\n",
    "                        else:\n",
    "                            traj.append(traj[-1])\n",
    "                    traj = dict([(i+1, traj[i]) for i in range(len(line))])\n",
    "                    per_cf_dc[horizon][tid][mode].append(traj)\n",
    "            \"\"\"\n",
    "            \n",
    "print(\"Missing %d entries\" % miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some stuff from disc and openml - takes some time\n",
    "tasks, task_ids_sorted_by_num_features = load_from_openml(task_ids)\n",
    "min_diff_dc = get_normalization_constants(dir_, load=True)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HORIZON = 60\n",
    "for tid in task_ids_sorted_by_num_features:\n",
    "    plt.figure(figsize=[8,6])\n",
    "    colors = itertools.cycle(style_dc[\"colors\"])\n",
    "    for mode in list(valid_pretty[HORIZON].keys()):\n",
    "        if not (\"3CV\" in mode[1] and \"SH\" not in mode[1]):\n",
    "            continue\n",
    "        c = next(colors)\n",
    "        #tmp = pd.DataFrame(per_cf_dc[HORIZON][tid][mode]).sort_index(axis=1).ffill(axis=1)\n",
    "        tmp = pd.DataFrame(res_dc[HORIZON][tid][mode]).sort_index(axis=1).ffill(axis=1)\n",
    "        med = tmp.median(axis=0)\n",
    "        med.loc[HORIZON*60] = med.iloc[-1]\n",
    "        low = tmp.quantile(0.25)\n",
    "        low.loc[HORIZON*60] = low.iloc[-1]\n",
    "        up = tmp.quantile(0.75, axis=0)\n",
    "        up.loc[HORIZON*60] = up.iloc[-1]\n",
    "        if mode[0] == 'knd':\n",
    "            label = valid_pretty[HORIZON][mode] + \" knd\"\n",
    "        elif mode[0] == 'bo':\n",
    "            label = valid_pretty[HORIZON][mode] + \" w/o\"\n",
    "        elif mode[0] == 'portfolio':\n",
    "            label = valid_pretty[HORIZON][mode] + \" portf\"\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        plt.plot(med.index, med.to_numpy(), label=label, linewidth=3)\n",
    "        \n",
    "        plt.fill_between(med.index, low, up, alpha=0.3)\n",
    "    plt.title('Name: %s (%d), #instances: %d, #attributes: %d' % (\n",
    "        tasks.loc[tid, 'name'], tid, tasks.loc[tid, 'NumberOfInstances'], tasks.loc[tid, 'NumberOfFeatures']))\n",
    "    plt.legend(fontsize=style_dc[\"fontsize\"])\n",
    "    plt.ylim([plt.ylim()[0], plt.ylim()[0] + 0.2*(plt.ylim()[1]-plt.ylim()[0])])\n",
    "    #plt.xscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average BER across all datasets\n",
    "HORIZON = 10\n",
    "tmp_dc = {HORIZON: {}}\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    if '10CV' not in m[1] or 'SH' in m[1]:\n",
    "        continue\n",
    "    model_list.append(m)\n",
    "    tmp_dc[HORIZON][m] = valid_pretty[HORIZON][m] + \" \" + str(m[0])\n",
    "\n",
    "average_plot(model_list=model_list, res_dc=res_dc, valid_pretty=tmp_dc,\n",
    "             horizon=HORIZON, task_ids_sorted_by_num_features=task_ids_sorted_by_num_features,\n",
    "             min_diff_dc=min_diff_dc)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average BER across all datasets\n",
    "HORIZON = 60\n",
    "tmp_dc = {HORIZON: {}}\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    if '10CV' not in m[1] or 'SH' in m[1]:\n",
    "        continue\n",
    "    model_list.append(m)\n",
    "    tmp_dc[HORIZON][m] = valid_pretty[HORIZON][m] + \" \" + str(m[0])\n",
    "\n",
    "average_plot(model_list=model_list, res_dc=res_dc, valid_pretty=tmp_dc,\n",
    "             horizon=HORIZON, task_ids_sorted_by_num_features=task_ids_sorted_by_num_features,\n",
    "             min_diff_dc=min_diff_dc)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final table\n",
    "tab_data = {}\n",
    "\n",
    "# Assume we have either all or no models\n",
    "horizon_list = sorted(list(valid_pretty.keys()))\n",
    "model_list = {}\n",
    "for h in horizon_list:\n",
    "    model_list[h] = []\n",
    "    for m in valid_pretty[h].keys():\n",
    "        model_list[h].append((m,valid_pretty[h][m]))\n",
    "\n",
    "stat_test_data = {}\n",
    "for horizon in horizon_list:\n",
    "    #tab_data[horizon] = {}\n",
    "    tab_data[str(horizon) + \" bo\"] = {}\n",
    "    tab_data[str(horizon) + \" Portfolio\"] = {}\n",
    "    tab_data[str(horizon) + \" KND\"] = {}\n",
    "    stat_test_data[horizon] = {}\n",
    "    stat_test_data[str(horizon) + \" bo\"] = {}\n",
    "    stat_test_data[str(horizon) + \" Portfolio\"] = {}\n",
    "    stat_test_data[str(horizon) + \" KND\"] = {}\n",
    "    #tab_data[\"STD %s\" % horizon] = {}\n",
    "\n",
    "    for mode in model_list[horizon]:\n",
    "        mode = mode[0]\n",
    "        assert mode in valid_pretty[horizon], (mode, valid_pretty[horizon].keys())\n",
    "        # Use label, not actual key\n",
    "        task_scores = []\n",
    "        seed_means = []\n",
    "        # Get means per tid\n",
    "        for tid in task_ids_sorted_by_num_features:\n",
    "            tmp = pd.DataFrame(res_dc[horizon][tid][mode]).sort_index(axis=1).ffill(axis=1)\n",
    "            tmp = (tmp - min_diff_dc[tid][0]) / min_diff_dc[tid][1]\n",
    "            task_scores.append(tmp.mean().iloc[-1])\n",
    "        # Get vars per seed\n",
    "        for s in range(10):\n",
    "            vals_for_this_seed = []\n",
    "            for tid in task_ids_sorted_by_num_features:\n",
    "                try:\n",
    "                    tmp_key = sorted(list(res_dc[horizon][tid][mode][s].keys()))[-1]\n",
    "                except IndexError:\n",
    "                    continue\n",
    "                tmp = res_dc[horizon][tid][mode][s][tmp_key]\n",
    "                tmp = (tmp - min_diff_dc[tid][0]) / min_diff_dc[tid][1]\n",
    "                vals_for_this_seed.append(tmp)\n",
    "            seed_means.append(np.mean(vals_for_this_seed))\n",
    "        seed_means = np.array(seed_means)\n",
    "        if mode[0] == 'knd':\n",
    "            tab_data[str(horizon) + \" KND\"][valid_pretty[horizon][mode]] = np.round(np.mean(task_scores)*100, 2)\n",
    "            stat_test_data[str(horizon) + \" KND\"][valid_pretty[horizon][mode]] = task_scores\n",
    "        elif mode[0] == 'bo':\n",
    "            tab_data[str(horizon) + \" bo\"][valid_pretty[horizon][mode]] = np.round(np.mean(task_scores)*100, 2)\n",
    "            stat_test_data[str(horizon) + \" bo\"][valid_pretty[horizon][mode]] = task_scores\n",
    "        elif mode[0] == 'portfolio':\n",
    "            tab_data[str(horizon) + \" Portfolio\"][valid_pretty[horizon][mode]] = np.round(np.mean(task_scores)*100, 2)\n",
    "            stat_test_data[str(horizon) + \" Portfolio\"][valid_pretty[horizon][mode]] = task_scores\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        #tab_data[\"STD %s\" % horizon][valid_pretty[horizon][mode]] = np.round(np.std(seed_means*100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"10 bo\", \"10 KND\", \"10 Portfolio\", \"60 bo\", \"60 KND\", \"60 Portfolio\"]\n",
    "tab_data = pd.DataFrame(tab_data)\n",
    "print(tab_data.columns)\n",
    "print(tab_data[['10 bo', '10 KND', '10 Portfolio', \n",
    "                '60 bo', '60 KND', '60 Portfolio']])\n",
    "print(pd.DataFrame(tab_data)[['10 bo', '10 KND', '10 Portfolio', \n",
    "                              '60 bo', '60 KND', '60 Portfolio']].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_different = {}\n",
    "for h in horizon_list:\n",
    "    not_different[h] = []\n",
    "    best = 100\n",
    "    best_m = None\n",
    "    for m1 in model_list[h]:\n",
    "        one, two, three = None, None, None\n",
    "        p1, p2, p3 = None, None, None\n",
    "        if m1[0][0] == 'portfolio':\n",
    "            one = stat_test_data[str(h) + ' Portfolio'][valid_pretty[h][m1[0]]]\n",
    "            p1 = np.mean(one)\n",
    "            # find method w/o port\n",
    "            for m2 in model_list[h]:\n",
    "                if m2[1] == m1[1] and m2[0][0] == 'bo':\n",
    "                    two = stat_test_data[str(h) + \" bo\"][valid_pretty[h][m2[0]]]\n",
    "                    p2 = np.mean(two)\n",
    "                    break\n",
    "            # find method k-nearest datasets\n",
    "            for m3 in model_list[h]:\n",
    "                if m3[1] == m1[1] and m3[0][0] == 'knd':\n",
    "                    three = stat_test_data[str(h) + \" KND\"][valid_pretty[h][m3[0]]]\n",
    "                    p3 = np.mean(three)\n",
    "                    break\n",
    "            assert one is not None\n",
    "            assert two is not None\n",
    "            assert three is not None\n",
    "            if p1 < p2 and p1 < p3:\n",
    "                opt = (one, m1)\n",
    "                chal = ((two, m2), (three, m3))\n",
    "            elif p2 < p1 and p2 < p3:\n",
    "                opt = (two, m2)\n",
    "                chal = ((one, m1), (three, m3))\n",
    "            elif p3 < p1 and p3 < p2:\n",
    "                opt = (three, m3)\n",
    "                chal = ((one, m1), (two, m2))\n",
    "            else:\n",
    "                raise ValueError()\n",
    "                continue\n",
    "            for c in chal:\n",
    "                s, p = scipy.stats.wilcoxon(x=opt[0], y=c[0], alternative=\"less\")\n",
    "                if p > 0.05:\n",
    "                    not_different[h].append((c[1][1], opt[1][0][0], c[1][0][0], \n",
    "                                             p, np.mean(opt[0])*100, np.mean(c[0])*100))\n",
    "\n",
    "for h in horizon_list:\n",
    "    print(\"Not different with %d mins:\\n\\t\" % h, \"\\n\\t\".join([\"%s: %s vs %s: %g (%g;%g)\" % n for n in not_different[h]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do ranking plot\n",
    "HORIZON = 60\n",
    "tmp_dc = {HORIZON: {}}\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    if \"holdout\" in m[1] and \"SH\" not in m[1]:\n",
    "        model_list.append(m)\n",
    "    add = m[0]\n",
    "    if len(add) < 4:\n",
    "        add = str.upper(add)\n",
    "    tmp_dc[HORIZON][m] = valid_pretty[HORIZON][m] + \" \" + str(add)\n",
    "    \n",
    "rank(model_list, res_dc, tmp_dc, HORIZON, task_ids_sorted_by_num_features, n_iter=200, steplength=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
