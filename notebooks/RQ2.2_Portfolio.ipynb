{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import openml\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "from plot_utils.style import style_dc\n",
    "from plot_utils.common_plots import rank, average_plot\n",
    "from plot_utils.common_tables import collect_data_for_final_table, do_wilcoxon_test\n",
    "from plot_utils.common_loading import load_from_openml\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/eggenspk/Work/Project/2020_PoSH_Autosklearn/2020_IEEE_Autosklearn_experiments/experiment_scripts/\")\n",
    "sys.path.append(\"/home/feurerm/sync_dir/projects/2020_posh/2020_IEEE_Autosklearn_experiments/experiment_scripts\")\n",
    "from utils import openml_automl_benchmark, get_normalization_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = ['#1b9e77','#d95f02','#7570b3','#e7298a','#66a61e','#e6ab02','#a6761d','#666666']\n",
    "FONTSIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = getpass.getuser()\n",
    "dir_ = {\n",
    "    'eggenspk': \"/home/eggenspk/Work/Project/2020_PoSH_Autosklearn/DATA/\",\n",
    "    'feurerm': \"/home/feurerm/projects/2020_posh/\",\n",
    "}[username]\n",
    "valid_pretty = {\n",
    "    60: {\n",
    "    (True, \"60MIN/RQ1_AutoAuto_simulate/dynamic/360/\"): \"With Portfolio (dynamic)\",\n",
    "    (True, \"60MIN/RQ1_AutoAuto_simulate/static/360/\"): \"With Portfolio (static)\",\n",
    "    #(False, \"60MIN/RQ1_AutoAuto_simulate/dynamic/360/\"): \"Only Portfolio\",\n",
    "    (True, \"60MIN/RQ2.2_AutoAuto_simulate/dynamic/360/\"): \"Without Portfolio (dynamic)\",\n",
    "    (True, \"60MIN/RQ2.2_AutoAuto_simulate/static/360/\"): \"Without Portfolio (static)\",\n",
    "    },\n",
    "}\n",
    "\n",
    "task_ids = openml_automl_benchmark\n",
    "\n",
    "res_dc = {}\n",
    "miss = 0\n",
    "fallback = 0\n",
    "for horizon in list(valid_pretty.keys()):\n",
    "    res_dc[horizon] = {}\n",
    "    for tid in task_ids:\n",
    "        res_dc[horizon][tid] = {}\n",
    "        for mode in list(valid_pretty[horizon].keys()):\n",
    "            res_dc[horizon][tid][mode] = []\n",
    "            for seed in range(10):\n",
    "                if not mode[0]:\n",
    "                    fl_tmpl = dir_ + mode[1] + \"autoauto_%d_%d/ensemble_results_0.000000thresh_50size_1.000000best_only_portfolio\" % (tid, seed)\n",
    "                else:\n",
    "                    fl_tmpl = dir_ + mode[1] + \"autoauto_%d_%d/ensemble_results_0.000000thresh_50size_1.000000best\" % (tid, seed)\n",
    "                fl = glob.glob(fl_tmpl)               \n",
    "                if len(fl) == 0:\n",
    "                    fl_tmpl = dir_ + mode[1] + \"autoauto_%d_%d/result.json\" % (tid, seed)\n",
    "                    fl = glob.glob(fl_tmpl)\n",
    "                    if len(fl) == 0:\n",
    "                        miss += 1\n",
    "                        print(fl_tmpl)\n",
    "                        continue\n",
    "                    else:\n",
    "                        fallback += 1\n",
    "                        print('Ensemble missing, falling back to regular', fl[0])\n",
    "                        pass\n",
    "                fl = fl[0]\n",
    "                with open(fl, \"r\") as fh:\n",
    "                    line = json.load(fh)\n",
    "                    if \"50\" in line:\n",
    "                        loss = line[\"50\"][\"trajectory\"]\n",
    "                    else:\n",
    "                        loss = line[\"0\"][\"trajectory\"]\n",
    "                    loss = [(l[0], l[1]) for l in loss]\n",
    "                    loss = dict(loss)\n",
    "                    res_dc[horizon][tid][mode].append(loss)\n",
    "print(\"Missing %d entries\" % miss)\n",
    "\n",
    "# There should be 7 fallbacks. These are all due to the statict strategy being 3-fold CV, which does\n",
    "# not work for the dionis dataset\n",
    "print(\"Fallback %d entries\" % fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some stuff from disc and openml - takes some time\n",
    "tasks, task_ids_sorted_by_num_features = load_from_openml(task_ids)\n",
    "min_diff_dc = get_normalization_constants(dir_, load=True)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HORIZON = 60\n",
    "for tid in task_ids_sorted_by_num_features:\n",
    "    plt.figure(figsize=[16,12])\n",
    "    colors = itertools.cycle(COLORS)\n",
    "    for mode in list(valid_pretty[HORIZON].keys()):\n",
    "        c = next(colors)\n",
    "        tmp = pd.DataFrame(res_dc[HORIZON][tid][mode]).sort_index(axis=1).ffill(axis=1)\n",
    "        med = tmp.median(axis=0)\n",
    "        med.loc[HORIZON*60] = med.iloc[-1]\n",
    "        low = tmp.quantile(0.25)\n",
    "        low.loc[HORIZON*60] = low.iloc[-1]\n",
    "        up = tmp.quantile(0.75, axis=0)\n",
    "        up.loc[HORIZON*60] = up.iloc[-1]\n",
    "        plt.plot(med.index, med.to_numpy(), label=valid_pretty[HORIZON][mode], linewidth=3)\n",
    "        plt.fill_between(med.index, low, up, alpha=0.3)\n",
    "    plt.title('Name: %s (%d), #instances: %d, #attributes: %d' % (\n",
    "        tasks.loc[tid, 'name'], tid, tasks.loc[tid, 'NumberOfInstances'], tasks.loc[tid, 'NumberOfFeatures']))\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.ylim([plt.ylim()[0], plt.ylim()[0] + 0.3*(plt.ylim()[1]-plt.ylim()[0])])\n",
    "    #plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot average BER across all datasets\n",
    "HORIZON = 60\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    model_list.append(m)\n",
    "\n",
    "average_plot(model_list=model_list, res_dc=res_dc, valid_pretty=valid_pretty,\n",
    "             horizon=HORIZON, task_ids_sorted_by_num_features=task_ids_sorted_by_num_features,\n",
    "             min_diff_dc=min_diff_dc)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume we have either all or no models\n",
    "horizon_list = sorted(list(valid_pretty.keys()))\n",
    "model_list = {}\n",
    "for h in horizon_list:\n",
    "    model_list[h] = []\n",
    "    for m in valid_pretty[h].keys():\n",
    "        model_list[h].append(m)\n",
    "\n",
    "tab_data, stat_test_data = collect_data_for_final_table(model_list, res_dc, valid_pretty, horizon_list,\n",
    "                                                        task_ids_sorted_by_num_features, min_diff_dc)\n",
    "not_different = do_wilcoxon_test(stat_test_data, model_list, horizon_list, valid_pretty, exclude=[\"Oracle\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tab_data)\n",
    "#for horizon in horizon_list:\n",
    "#    df['Rank_%s' % horizon] = df[horizon].rank(method='average', ascending=True)\n",
    "print(df)\n",
    "print(df.to_latex())\n",
    "print(not_different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 60\n",
    "model_list = []\n",
    "for m in valid_pretty[HORIZON].keys():\n",
    "    model_list.append(m)\n",
    "rank(model_list, res_dc, valid_pretty, HORIZON, task_ids_sorted_by_num_features, n_iter=200, steplength=5)\n",
    "plt.legend(fontsize=style_dc[\"fontsize\"], loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
